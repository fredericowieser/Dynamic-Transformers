# Defines metadata for the run, output directories, and hardware settings.
run_params:
  name: "gpt2_sanity_check"
  output_dir: "outputs/${run_params.name}" # Hydra automatically creates this directory
  seed: 42
  device: "auto" # Let PyTorch Lightning auto-detect accelerator (cuda, mps, cpu)
  precision: "32-true" # "bf16-mixed" or "16-mixed" for faster training on supported GPUs

# Configures the dataset, tokenization, and data loading.
data_params:
  # The _target_ key tells Hydra which Python class to instantiate.
  _target_: dynamic_transformer.data.HuggingFaceDataModule
  dataset_name: "wikitext"
  dataset_config: "wikitext-2-raw-v1"
  tokenizer_name: "gpt2" # Use the tokenizer corresponding to the model
  block_size: 256 # Context length for the model
  batch_size: 16 # Number of sequences per batch

# Defines the model architecture and its initial weights.
model_params:
  _target_: dynamic_transformer.models.base.HuggingFaceModel
  # The Hugging Face model identifier to load.
  base_model_id: "gpt2"

# Specifies hyperparameters for the training process, like optimizer settings.
training_params:
  learning_rate: 3.0e-5
  max_iters: 2000
  eval_interval: 250 # How often to run validation (in training steps)
  eval_iters: 200 # How many batches to use for each validation run
  optimizer_name: "AdamW"
  # AdamW specific params
  weight_decay: 0.01
  beta1: 0.9
  beta2: 0.999

# LoRA
# Configuration for Parameter-Efficient Fine-Tuning techniques like LoRA.
lora_params:
  enabled: false # Set to true to enable LoRA
  r: 8 # LoRA rank
  lora_alpha: 16 # LoRA alpha scaling factor
  lora_dropout: 0.05
  # List of module names within the model to apply LoRA to.
  # For GPT-2, this is typically the attention projection layer.
  target_modules:
    - "c_attn"

# Logging Parameters
logging_params:
  tensorboard:
    enabled: true
  wandb:
    enabled: false # Set to true to enable WandB logging
    project: "dynamic_transformer"
    entity: null # MUST be overridden by the user (e.g., your WandB username)

# Final Evaluation Flag
# A top-level flag to control whether to run the test set evaluation after training.
run_final_evaluation: true