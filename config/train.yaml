# @package _global_

defaults:
  - _self_
  - system: default
  - model: default
  - data: default
  - training: default
  - logging: default
  - override hydra/job_logging: default
  - override hydra/hydra_logging: default

hydra:
  run:
    dir: outputs/${run.name}

run:
  name: "qwen2.5-${model.size}-${model.type}-${training.mode}-${now:%Y-%m-%d_%H-%M-%S}"
  output_dir: "outputs/${run.name}"
  seed: 42
  run_final_evaluation: True

# PEFT (LoRA) configuration
peft:
  enabled: False
  config:
    _target_: peft.LoraConfig
    r: 16
    lora_alpha: 32
    target_modules:
      - "q_proj"
      - "k_proj"
      - "v_proj"
      - "o_proj"
      - "gate_proj"
      - "up_proj"
      - "down_proj"
    modules_to_save:
      - "prior_ffn"
      - "router"
    lora_dropout: 0.05
    bias: "none"
    task_type: "CAUSAL_LM"

# Push to Hugging Face Hub
push_to_hub:
  enabled: False
  repo_id: "your-username/your-model-id"
  commit_message: "Trained model with Dynamic Transformer"
  private: False

# lm_eval configuration
lm_eval:
  enabled: False
  tasks: ["arc_challenge", "hellaswag", "mmlu", "winogrande", "truthfulqa_mc2"]
  batch_size: 8
  merge_lora_for_eval: True
