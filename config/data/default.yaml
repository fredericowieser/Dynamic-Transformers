# @package _global_

data:
  name: "pretrain_mix"
  batch_size: 16
  tokenizer_name: "Qwen/Qwen2.5-${model.size}"
  block_size: 1024
  validation_split_percentage: 2
  dataset_configs:
    - type: "pretrain"
      dataset_name: "wikitext"
      dataset_config: "wikitext-103-raw-v1"
      text_column: "text"
      train_subset_ratio: 1.0
    - type: "pretrain"
      dataset_name: "cnn_dailymail"
      dataset_config: "3.0.0"
      text_column: "article"
      train_subset_ratio: 0.2
    - type: "pretrain"
      dataset_name: "storytracer/US-PD-Books"
      text_column: "text"
      train_subset_ratio: 0.5
    - type: "pretrain"
      dataset_name: "HuggingFaceTB/cosmopedia"
      dataset_config: "openstax"
      text_column: "text"
      train_subset_ratio: 0.1
    - type: "pretrain"
      dataset_name: "sciq"
      text_column: "support"
      train_subset_ratio: 1.0
    - type: "pretrain"
      dataset_name: "codeparrot/codeparrot-clean-valid"
      text_column: "content"
      train_subset_ratio: 1.0
    - type: "pretrain"
      dataset_name: "roneneldan/TinyStories"
      text_column: "text"
      train_subset_ratio: 1.0
