model:
  type: tdtf
  size: 0.5B
data:
  dataset_name: wikitext
  dataset_config: wikitext-103-raw-v1
  split: train
  max_length: 256
  batch_size: 16
  shuffle: true
  num_workers: 4
training:
  num_epochs: 1
  max_steps: 100
  gradient_accumulation_steps: 1
  gradient_clip_val: 1.0
  eval_interval: 50
  eval_samples: 100
  from_scratch: false
  optimizer:
    lr: 0.0001
    weight_decay: 0.01
    adam_beta1: 0.9
    adam_beta2: 0.999
    adam_epsilon: 1.0e-08
    scheduler: cosine
    warmup_ratio: 0.1
system:
  output_dir: outputs/test_tdtf_${now:%Y%m%d_%H%M%S}
  compile: false
  num_workers: 4
  seed: 42
logging:
  log_interval: 10
  save_interval: 50
  eval_interval: 50
tdtf:
  tpn_intermediate_size_factor: 0.25
  tpn_loss_weight: 1.0
  causal_loss_weight: 1.0
  capacity: 0.5
  o_ce_init: 1.025
  m_cu_init: 1.1
  beta_ce_init: -0.3
  beta_cu_init: -0.6
  ma_window: 100
